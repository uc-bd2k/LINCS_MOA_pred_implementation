{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINCS MOA classification for LINCS curated using Logistic regression(linear classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prostate=pd.read_hdf(\"/opt/raid10/genomics/rashid/GCN/data/GSE92742_fully_restricted.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate=file_prostate.reset_index(level=[0,1,2,3,4,5,6]) #change from multi index to single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_y=df_prostate[\"moa\"].values #change moa column to numpy array\n",
    "df_prostate= df_prostate.drop(columns=[\"pert_id\",\"pert_name\",\"cell_id\",\"primary_site\",\"subtype\",\"moa\",\"Fold\"])\n",
    "prostate_X=df_prostate.values #get the matrix of feature values for 978 genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,uniques=pd.factorize(prostate_y) #labels are the encodings\n",
    "prostate_y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "prostate_X=sc.fit_transform(prostate_X) #normalize feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA\n",
    "X_train,X_test,y_train,y_test=train_test_split(prostate_X,prostate_y,test_size=0.2,random_state=42)#split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lc = SGDClassifier()\n",
    "lc.fit(X_train,y_train)\n",
    "pred_lc=lc.predict(X_test)  #3-4 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    3    1 ...   15  530    0]\n",
      " [   1    4    3 ...   12  635    0]\n",
      " [   2    3   10 ...   20  563    0]\n",
      " ...\n",
      " [   0    8    3 ... 1765 1484  105]\n",
      " [   3   24   14 ...  223 4635    2]\n",
      " [   0    0    0 ...  329  403   94]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.04      0.01      0.01       710\n",
      "           2       0.16      0.02      0.03       634\n",
      "           3       0.72      0.13      0.22       453\n",
      "           4       0.00      0.00      0.00       205\n",
      "           5       0.07      0.00      0.00       588\n",
      "           6       1.00      0.03      0.06       212\n",
      "           7       0.00      0.00      0.00       441\n",
      "           8       0.95      0.58      0.72       859\n",
      "           9       0.00      0.00      0.00       433\n",
      "          10       0.00      0.00      0.00       337\n",
      "          11       0.00      0.00      0.00       290\n",
      "          12       0.22      0.00      0.01       487\n",
      "          13       0.95      0.39      0.55       253\n",
      "          14       0.32      0.12      0.17      1222\n",
      "          15       0.65      0.06      0.12       380\n",
      "          16       0.00      0.00      0.00       220\n",
      "          17       0.06      0.01      0.01       693\n",
      "          18       0.08      0.01      0.02       825\n",
      "          19       0.00      0.00      0.00       238\n",
      "          20       0.49      0.10      0.17       547\n",
      "          21       0.12      0.00      0.01       566\n",
      "          22       0.58      0.54      0.56       544\n",
      "          23       0.74      0.24      0.37       262\n",
      "          24       0.86      0.38      0.53       364\n",
      "          25       0.00      0.00      0.00       227\n",
      "          26       0.58      0.54      0.56      2909\n",
      "          27       0.84      0.10      0.17       321\n",
      "          28       0.00      0.00      0.00       210\n",
      "          29       0.47      0.06      0.10       673\n",
      "          30       0.83      0.40      0.54       456\n",
      "          31       0.00      0.00      0.00       232\n",
      "          32       1.00      0.02      0.03       170\n",
      "          33       0.00      0.00      0.00       575\n",
      "          34       0.00      0.00      0.00       187\n",
      "          35       1.00      0.01      0.02       246\n",
      "          36       0.48      0.03      0.06       458\n",
      "          37       0.68      0.06      0.11       378\n",
      "          38       0.12      0.01      0.01       342\n",
      "          39       0.41      0.07      0.12       212\n",
      "          40       0.55      0.05      0.09       255\n",
      "          41       0.33      0.00      0.01       256\n",
      "          42       0.85      0.17      0.28       364\n",
      "          43       1.00      0.07      0.13       203\n",
      "          44       0.80      0.03      0.06       478\n",
      "          45       0.72      0.07      0.12       267\n",
      "          46       0.62      0.51      0.56      3479\n",
      "          47       0.21      0.89      0.34      5212\n",
      "          48       0.45      0.11      0.18       837\n",
      "\n",
      "   micro avg       0.32      0.32      0.32     31293\n",
      "   macro avg       0.41      0.12      0.14     31293\n",
      "weighted avg       0.40      0.32      0.26     31293\n",
      "\n",
      "0.31703575879589685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_lc))\n",
    "print(classification_report(y_test,pred_lc))\n",
    "acc_lc=accuracy_score(y_test,pred_lc) #result for linear classification\n",
    "print(acc_lc) #print precision score \n",
    "#results doesn't quite matches in the paper where accuracy is 63.8 ± 0.52, macro F1 is 42.6 ± 1.03. Took 3-4 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linearClassifier_MOA_FullCurated_notTuned']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lc,'linearClassifier_MOA_FullCurated_notTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_benchmark = SGDClassifier(eta0= 0.00031685190815167104, l1_ratio= 0.40558624196055393, tol=1e-05, penalty='l1', random_state= 101, max_iter= 1000, learning_rate= 'invscaling', alpha= 0.0012311722512335377, n_jobs= -1, power_t= 0.1840171707888663, loss= 'log')\n",
    "lc_benchmark.fit(X_train,y_train)\n",
    "pred_lc_benchmark=lc_benchmark.predict(X_test)  #3-4 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    1 ...   48  476    1]\n",
      " [   0    0    0 ...   53  574    1]\n",
      " [   0    0    1 ...   68  519    1]\n",
      " ...\n",
      " [   0    0    1 ... 2559  861    3]\n",
      " [   0    0    1 ...  398 4711    5]\n",
      " [   0    0    0 ...  688  138    6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.00      0.00      0.00       710\n",
      "           2       0.10      0.00      0.00       634\n",
      "           3       0.55      0.19      0.28       453\n",
      "           4       0.00      0.00      0.00       205\n",
      "           5       0.00      0.00      0.00       588\n",
      "           6       1.00      0.02      0.05       212\n",
      "           7       0.00      0.00      0.00       441\n",
      "           8       0.83      0.71      0.77       859\n",
      "           9       0.00      0.00      0.00       433\n",
      "          10       0.00      0.00      0.00       337\n",
      "          11       0.00      0.00      0.00       290\n",
      "          12       0.00      0.00      0.00       487\n",
      "          13       0.89      0.47      0.62       253\n",
      "          14       0.32      0.27      0.29      1222\n",
      "          15       0.38      0.04      0.08       380\n",
      "          16       0.00      0.00      0.00       220\n",
      "          17       0.00      0.00      0.00       693\n",
      "          18       0.12      0.01      0.01       825\n",
      "          19       0.00      0.00      0.00       238\n",
      "          20       0.36      0.08      0.13       547\n",
      "          21       0.00      0.00      0.00       566\n",
      "          22       0.76      0.40      0.53       544\n",
      "          23       0.60      0.37      0.46       262\n",
      "          24       0.79      0.62      0.69       364\n",
      "          25       0.00      0.00      0.00       227\n",
      "          26       0.63      0.66      0.64      2909\n",
      "          27       0.63      0.16      0.26       321\n",
      "          28       0.00      0.00      0.00       210\n",
      "          29       0.34      0.13      0.18       673\n",
      "          30       0.63      0.68      0.66       456\n",
      "          31       0.00      0.00      0.00       232\n",
      "          32       1.00      0.02      0.05       170\n",
      "          33       0.00      0.00      0.00       575\n",
      "          34       0.00      0.00      0.00       187\n",
      "          35       0.50      0.01      0.02       246\n",
      "          36       0.00      0.00      0.00       458\n",
      "          37       0.58      0.10      0.16       378\n",
      "          38       0.00      0.00      0.00       342\n",
      "          39       0.37      0.09      0.14       212\n",
      "          40       0.47      0.11      0.17       255\n",
      "          41       0.50      0.00      0.01       256\n",
      "          42       0.65      0.30      0.41       364\n",
      "          43       0.92      0.05      0.10       203\n",
      "          44       0.57      0.04      0.08       478\n",
      "          45       0.56      0.13      0.21       267\n",
      "          46       0.47      0.74      0.58      3479\n",
      "          47       0.25      0.90      0.40      5212\n",
      "          48       0.11      0.01      0.01       837\n",
      "\n",
      "   micro avg       0.37      0.37      0.37     31293\n",
      "   macro avg       0.32      0.15      0.16     31293\n",
      "weighted avg       0.33      0.37      0.29     31293\n",
      "\n",
      "0.3725433803086952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_lc_benchmark))\n",
    "print(classification_report(y_test,pred_lc_benchmark))\n",
    "acc_lc_benchmark=accuracy_score(y_test,pred_lc_benchmark) #result for linear classification\n",
    "print(acc_lc_benchmark) #print precision score \n",
    "#result matches with actual benchmark test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linearClassifier_MOA_FullCurated_Tuned']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(lc_benchmark,'linearClassifier_MOA_FullCurated_Tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
