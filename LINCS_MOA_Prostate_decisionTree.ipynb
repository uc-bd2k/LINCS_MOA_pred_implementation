{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINCS MOA prediciton for LINCS curated using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prostate=pd.read_hdf(\"/Users/Rashid/Desktop/Rashid/Career/PhD/Research/projects/GCN/data/GSE92742_fully_restricted_prostate.hdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate=file_prostate.reset_index(level=[0,1,2,3,4,5,6]) #change from multi index to single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_y=df_prostate[\"moa\"].values #change moa column to numpy array\n",
    "df_prostate= df_prostate.drop(columns=[\"pert_id\",\"pert_name\",\"cell_id\",\"primary_site\",\"subtype\",\"moa\",\"Fold\"])\n",
    "prostate_X=df_prostate.values #get the matrix of feature values for 978 genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,uniques=pd.factorize(prostate_y) #labels are the encodings\n",
    "prostate_y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "prostate_X=sc.fit_transform(prostate_X) #normalize feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA\n",
    "X_train,X_test,y_train,y_test=train_test_split(prostate_X,prostate_y,test_size=0.2,random_state=42)#split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = DecisionTreeClassifier()\n",
    "dct.fit(X_train,y_train)\n",
    "pred_dct=dct.predict(X_test)  #1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25   0  22  15  11  12  32 113   9]\n",
      " [  9 142  10   0   3   8  18  31   1]\n",
      " [ 26   8 125  32  15  36  53 127   6]\n",
      " [ 14   1  31  18  18  10  31  89   7]\n",
      " [ 10   4  16   9  23  22  29  84   7]\n",
      " [ 21  11  30  13  23 659  29 124  17]\n",
      " [ 26  11  42  33  40  47 388 249  66]\n",
      " [104  42 114  78  99 125 269 860  55]\n",
      " [  5   2  13   5  12  14  86  55  34]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.10      0.10       239\n",
      "           1       0.64      0.64      0.64       222\n",
      "           2       0.31      0.29      0.30       428\n",
      "           3       0.09      0.08      0.09       219\n",
      "           4       0.09      0.11      0.10       204\n",
      "           5       0.71      0.71      0.71       927\n",
      "           6       0.41      0.43      0.42       902\n",
      "           7       0.50      0.49      0.49      1746\n",
      "           8       0.17      0.15      0.16       226\n",
      "\n",
      "    accuracy                           0.44      5113\n",
      "   macro avg       0.34      0.34      0.34      5113\n",
      "weighted avg       0.44      0.44      0.44      5113\n",
      "\n",
      "0.44474867983571287\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_dct))\n",
    "print(classification_report(y_test,pred_dct))\n",
    "acc_dct=accuracy_score(y_test,pred_dct) #result for svm\n",
    "print(acc_dct) #print precision score \n",
    "#results doesn't quite matches in the paper where accuracy is 53.2 ± 1.16, macro F1 is 32.6 ± 0.91. Took 4-5 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_benchmark=DecisionTreeClassifier(min_impurity_decrease=0.0014646397820345471, min_samples_leaf= 1, min_weight_fraction_leaf=0.00018089997347969574, max_depth=25, max_features=250, criterion= 'entropy', max_leaf_nodes=None, min_samples_split=2, splitter='best')\n",
    "dct_benchmark.fit(X_train,y_train)\n",
    "pred_dct_benchmark=dct_benchmark.predict(X_test)  #1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    2   21    0    0   10   22  183    0]\n",
      " [   0  142    9    0    0   10    6   55    0]\n",
      " [   6    7  132    0    0   14   32  237    0]\n",
      " [   3    1   35    0    0    4   19  157    0]\n",
      " [   0    1    3    0    1    7   21  171    0]\n",
      " [   0    4   18    0    0  540   36  329    0]\n",
      " [   0    8   12    0    0   19  366  497    0]\n",
      " [   0   14   25    0    0   50  158 1499    0]\n",
      " [   0    0    1    0    0    2  105  118    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.00      0.01       239\n",
      "           1       0.79      0.64      0.71       222\n",
      "           2       0.52      0.31      0.39       428\n",
      "           3       0.00      0.00      0.00       219\n",
      "           4       1.00      0.00      0.01       204\n",
      "           5       0.82      0.58      0.68       927\n",
      "           6       0.48      0.41      0.44       902\n",
      "           7       0.46      0.86      0.60      1746\n",
      "           8       0.00      0.00      0.00       226\n",
      "\n",
      "    accuracy                           0.52      5113\n",
      "   macro avg       0.46      0.31      0.31      5113\n",
      "weighted avg       0.51      0.52      0.47      5113\n",
      "\n",
      "0.5243496968511637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/scikitLearnTutorial/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_dct_benchmark))\n",
    "print(classification_report(y_test,pred_dct_benchmark))\n",
    "acc_dct_benchmark=accuracy_score(y_test,pred_dct_benchmark) #result for svm\n",
    "print(acc_dct_benchmark) #print precision score \n",
    "#results almost matches in the paper where accuracy is 53.2 ± 1.16, macro F1 is 32.6 ± 0.91. Took 4-5 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scikitLearnTutorial]",
   "language": "python",
   "name": "conda-env-scikitLearnTutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
