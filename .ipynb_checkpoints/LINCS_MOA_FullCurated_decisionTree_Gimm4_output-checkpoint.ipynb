{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINCS MOA prediciton for LINCS curated using decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prostate=pd.read_hdf(\"/opt/raid10/genomics/rashid/GCN/data/GSE92742_fully_restricted.hdf\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate=file_prostate.reset_index(level=[0,1,2,3,4,5,6]) #change from multi index to single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_y=df_prostate[\"moa\"].values #change moa column to numpy array\n",
    "df_prostate= df_prostate.drop(columns=[\"pert_id\",\"pert_name\",\"cell_id\",\"primary_site\",\"subtype\",\"moa\",\"Fold\"])\n",
    "prostate_X=df_prostate.values #get the matrix of feature values for 978 genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,uniques=pd.factorize(prostate_y) #labels are the encodings\n",
    "prostate_y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "prostate_X=sc.fit_transform(prostate_X) #normalize feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA\n",
    "X_train,X_test,y_train,y_test=train_test_split(prostate_X,prostate_y,test_size=0.2,random_state=42)#split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = DecisionTreeClassifier()\n",
    "dct.fit(X_train,y_train)\n",
    "pred_dct=dct.predict(X_test)  #1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  21   21   22 ...   51  111    9]\n",
      " [  17   32   18 ...   50  149   16]\n",
      " [  11   26   22 ...   62  128   13]\n",
      " ...\n",
      " [  45   61   57 ... 1339  422  274]\n",
      " [ 133  167  113 ...  424 1468  111]\n",
      " [   6   12   20 ...  261  101  118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.04      0.04       583\n",
      "           1       0.04      0.05      0.04       710\n",
      "           2       0.03      0.03      0.03       634\n",
      "           3       0.13      0.12      0.13       453\n",
      "           4       0.03      0.03      0.03       205\n",
      "           5       0.04      0.04      0.04       588\n",
      "           6       0.05      0.04      0.05       212\n",
      "           7       0.04      0.03      0.03       441\n",
      "           8       0.58      0.54      0.56       859\n",
      "           9       0.03      0.03      0.03       433\n",
      "          10       0.01      0.01      0.01       337\n",
      "          11       0.01      0.01      0.01       290\n",
      "          12       0.03      0.03      0.03       487\n",
      "          13       0.33      0.33      0.33       253\n",
      "          14       0.13      0.14      0.13      1222\n",
      "          15       0.13      0.13      0.13       380\n",
      "          16       0.03      0.03      0.03       220\n",
      "          17       0.04      0.04      0.04       693\n",
      "          18       0.07      0.08      0.07       825\n",
      "          19       0.01      0.01      0.01       238\n",
      "          20       0.06      0.06      0.06       547\n",
      "          21       0.02      0.02      0.02       566\n",
      "          22       0.61      0.55      0.58       544\n",
      "          23       0.18      0.18      0.18       262\n",
      "          24       0.39      0.37      0.38       364\n",
      "          25       0.01      0.01      0.01       227\n",
      "          26       0.59      0.64      0.61      2909\n",
      "          27       0.08      0.08      0.08       321\n",
      "          28       0.02      0.02      0.02       210\n",
      "          29       0.11      0.10      0.10       673\n",
      "          30       0.39      0.38      0.38       456\n",
      "          31       0.01      0.01      0.01       232\n",
      "          32       0.09      0.08      0.09       170\n",
      "          33       0.02      0.02      0.02       575\n",
      "          34       0.00      0.00      0.00       187\n",
      "          35       0.06      0.05      0.05       246\n",
      "          36       0.04      0.04      0.04       458\n",
      "          37       0.14      0.13      0.13       378\n",
      "          38       0.04      0.04      0.04       342\n",
      "          39       0.10      0.10      0.10       212\n",
      "          40       0.12      0.11      0.11       255\n",
      "          41       0.03      0.03      0.03       256\n",
      "          42       0.24      0.22      0.23       364\n",
      "          43       0.08      0.07      0.07       203\n",
      "          44       0.09      0.09      0.09       478\n",
      "          45       0.18      0.14      0.16       267\n",
      "          46       0.40      0.38      0.39      3479\n",
      "          47       0.29      0.28      0.28      5212\n",
      "          48       0.14      0.14      0.14       837\n",
      "\n",
      "   micro avg       0.22      0.22      0.22     31293\n",
      "   macro avg       0.13      0.12      0.13     31293\n",
      "weighted avg       0.22      0.22      0.22     31293\n",
      "\n",
      "0.22433132010353754\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_dct))\n",
    "print(classification_report(y_test,pred_dct))\n",
    "acc_dct=accuracy_score(y_test,pred_dct) #result for svm\n",
    "print(acc_dct) #print precision score \n",
    "#results doesn't quite matches in the paper where accuracy is 53.2 ± 1.16, macro F1 is 32.6 ± 0.91. Took 4-5 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decisionTree_MOA_FullCurated_notTuned']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(dct,'decisionTree_MOA_FullCurated_notTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_benchmark=DecisionTreeClassifier(min_impurity_decrease=0.0012257673197162205, min_samples_leaf= 2, min_weight_fraction_leaf=0.0020780796100258966, max_depth=10, max_features=None, criterion= 'entropy', max_leaf_nodes=None, min_samples_split=2, splitter='best')\n",
    "dct_benchmark.fit(X_train,y_train)\n",
    "pred_dct_benchmark=dct_benchmark.predict(X_test)  #1 min!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...   30  503    0]\n",
      " [   0    0    0 ...   50  565    0]\n",
      " [   0    0    0 ...   43  544    0]\n",
      " ...\n",
      " [   0    0    0 ... 1194 2085    0]\n",
      " [   0    0    0 ...  309 4706    0]\n",
      " [   0    0    0 ...  353  464    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.00      0.00      0.00       710\n",
      "           2       0.00      0.00      0.00       634\n",
      "           3       0.22      0.11      0.15       453\n",
      "           4       0.00      0.00      0.00       205\n",
      "           5       0.00      0.00      0.00       588\n",
      "           6       0.00      0.00      0.00       212\n",
      "           7       0.00      0.00      0.00       441\n",
      "           8       0.56      0.58      0.57       859\n",
      "           9       0.00      0.00      0.00       433\n",
      "          10       0.00      0.00      0.00       337\n",
      "          11       0.00      0.00      0.00       290\n",
      "          12       0.00      0.00      0.00       487\n",
      "          13       0.42      0.19      0.26       253\n",
      "          14       0.27      0.22      0.24      1222\n",
      "          15       0.16      0.08      0.11       380\n",
      "          16       0.00      0.00      0.00       220\n",
      "          17       0.00      0.00      0.00       693\n",
      "          18       0.00      0.00      0.00       825\n",
      "          19       0.00      0.00      0.00       238\n",
      "          20       0.00      0.00      0.00       547\n",
      "          21       0.00      0.00      0.00       566\n",
      "          22       0.00      0.00      0.00       544\n",
      "          23       0.37      0.08      0.13       262\n",
      "          24       0.29      0.24      0.26       364\n",
      "          25       0.00      0.00      0.00       227\n",
      "          26       0.57      0.57      0.57      2909\n",
      "          27       0.12      0.08      0.10       321\n",
      "          28       0.00      0.00      0.00       210\n",
      "          29       0.17      0.09      0.12       673\n",
      "          30       0.47      0.38      0.42       456\n",
      "          31       0.00      0.00      0.00       232\n",
      "          32       0.00      0.00      0.00       170\n",
      "          33       0.00      0.00      0.00       575\n",
      "          34       0.00      0.00      0.00       187\n",
      "          35       0.00      0.00      0.00       246\n",
      "          36       0.00      0.00      0.00       458\n",
      "          37       0.27      0.07      0.11       378\n",
      "          38       0.00      0.00      0.00       342\n",
      "          39       0.09      0.06      0.07       212\n",
      "          40       0.00      0.00      0.00       255\n",
      "          41       0.00      0.00      0.00       256\n",
      "          42       0.44      0.22      0.29       364\n",
      "          43       0.00      0.00      0.00       203\n",
      "          44       0.00      0.00      0.00       478\n",
      "          45       0.25      0.06      0.09       267\n",
      "          46       0.40      0.34      0.37      3479\n",
      "          47       0.22      0.90      0.36      5212\n",
      "          48       0.00      0.00      0.00       837\n",
      "\n",
      "   micro avg       0.29      0.29      0.29     31293\n",
      "   macro avg       0.11      0.09      0.09     31293\n",
      "weighted avg       0.20      0.29      0.20     31293\n",
      "\n",
      "0.2864857955453296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_dct_benchmark))\n",
    "print(classification_report(y_test,pred_dct_benchmark))\n",
    "acc_dct_benchmark=accuracy_score(y_test,pred_dct_benchmark) #result for svm\n",
    "print(acc_dct_benchmark) #print precision score \n",
    "#results almost matches in the paper where accuracy is 53.2 ± 1.16, macro F1 is 32.6 ± 0.91. Took 4-5 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decisionTree_MOA_FullCurated_Tuned']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(dct_benchmark,'decisionTree_MOA_FullCurated_Tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
