{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINCS MOA classifcation for LINCS curated using Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prostate=pd.read_hdf(\"/opt/raid10/genomics/rashid/GCN/data/GSE92742_fully_restricted.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prostate=file_prostate.reset_index(level=[0,1,2,3,4,5,6]) #change from multi index to single index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prostate_y=df_prostate[\"moa\"].values #change moa column to numpy array\n",
    "df_prostate= df_prostate.drop(columns=[\"pert_id\",\"pert_name\",\"cell_id\",\"primary_site\",\"subtype\",\"moa\",\"Fold\"])\n",
    "prostate_X=df_prostate.values #get the matrix of feature values for 978 genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,uniques=pd.factorize(prostate_y) #labels are the encodings\n",
    "prostate_y=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "prostate_X=sc.fit_transform(prostate_X) #normalize feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DATA\n",
    "X_train,X_test,y_train,y_test=train_test_split(prostate_X,prostate_y,test_size=0.2,random_state=42)#split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpc=MLPClassifier(hidden_layer_sizes=(997),max_iter=350) #max_iter goes through the layers 350 times(forward pass and backpropagation) to adjust weights\n",
    "mlpc.fit(X_train,y_train)\n",
    "pred_mlpc=mlpc.predict(X_test) #around 5 mins tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  26   31   13 ...   12  113    5]\n",
      " [  17   70   25 ...   12  126    2]\n",
      " [  17   37   66 ...   27  112    5]\n",
      " ...\n",
      " [  14   23   15 ... 2285  243  425]\n",
      " [  84  139   87 ...  178 2587   32]\n",
      " [   5    5    2 ...  341   32  379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.04      0.05       583\n",
      "           1       0.08      0.10      0.09       710\n",
      "           2       0.12      0.10      0.11       634\n",
      "           3       0.49      0.29      0.36       453\n",
      "           4       0.05      0.03      0.04       205\n",
      "           5       0.07      0.08      0.08       588\n",
      "           6       0.18      0.16      0.17       212\n",
      "           7       0.06      0.06      0.06       441\n",
      "           8       0.81      0.73      0.77       859\n",
      "           9       0.05      0.06      0.06       433\n",
      "          10       0.04      0.05      0.04       337\n",
      "          11       0.03      0.04      0.03       290\n",
      "          12       0.07      0.06      0.07       487\n",
      "          13       0.54      0.63      0.58       253\n",
      "          14       0.25      0.23      0.24      1222\n",
      "          15       0.44      0.30      0.35       380\n",
      "          16       0.03      0.05      0.04       220\n",
      "          17       0.10      0.08      0.09       693\n",
      "          18       0.08      0.13      0.10       825\n",
      "          19       0.03      0.02      0.02       238\n",
      "          20       0.27      0.25      0.26       547\n",
      "          21       0.05      0.04      0.04       566\n",
      "          22       0.85      0.77      0.81       544\n",
      "          23       0.59      0.58      0.59       262\n",
      "          24       0.83      0.73      0.77       364\n",
      "          25       0.08      0.06      0.07       227\n",
      "          26       0.76      0.80      0.78      2909\n",
      "          27       0.48      0.42      0.45       321\n",
      "          28       0.05      0.02      0.03       210\n",
      "          29       0.22      0.30      0.25       673\n",
      "          30       0.74      0.84      0.78       456\n",
      "          31       0.08      0.10      0.09       232\n",
      "          32       0.48      0.50      0.49       170\n",
      "          33       0.10      0.07      0.08       575\n",
      "          34       0.03      0.03      0.03       187\n",
      "          35       0.26      0.15      0.19       246\n",
      "          36       0.23      0.24      0.23       458\n",
      "          37       0.41      0.32      0.36       378\n",
      "          38       0.19      0.17      0.18       342\n",
      "          39       0.35      0.55      0.43       212\n",
      "          40       0.33      0.38      0.36       255\n",
      "          41       0.40      0.32      0.35       256\n",
      "          42       0.55      0.51      0.53       364\n",
      "          43       0.49      0.38      0.43       203\n",
      "          44       0.38      0.33      0.35       478\n",
      "          45       0.63      0.49      0.55       267\n",
      "          46       0.70      0.66      0.68      3479\n",
      "          47       0.46      0.50      0.48      5212\n",
      "          48       0.40      0.45      0.43       837\n",
      "\n",
      "   micro avg       0.40      0.40      0.40     31293\n",
      "   macro avg       0.31      0.29      0.29     31293\n",
      "weighted avg       0.40      0.40      0.40     31293\n",
      "\n",
      "0.3989071038251366\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_mlpc))\n",
    "print(classification_report(y_test,pred_mlpc))\n",
    "acc_mlpc=accuracy_score(y_test,pred_mlpc) #result for svm\n",
    "print(acc_mlpc) #print precision score \n",
    "#results matches in the paper where accuracy is 68.3 ± 0.60, macro F1 is 50.4 ± 0.71. Took 4-5 minutes on macbook pro 2.7 GHz inter core i5 processor, 16 GB 1867 MHz DDR3 Memomry, Intel Iris Graphics 6100 1536 MB Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFNN_MOA_FullCurated_notTuned']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(mlpc,'FFNN_MOA_FullCurated_notTuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (164) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlpc_benchmark=MLPClassifier(beta_1= 0.919473939313036, activation='relu', alpha= 1.6879174708893805, epsilon=9.7045902021921481e-10, solver= 'sgd', power_t= 0.33021989249044037, learning_rate_init= 0.10898026569061127, hidden_layer_sizes= (955), max_iter= 164, beta_2= 0.99919431656457547, learning_rate= 'adaptive', momentum= 0.86370430284520194, early_stopping= True, nesterovs_momentum= True) #max_iter goes through the layers 350 times(forward pass and backpropagation) to adjust weights\n",
    "mlpc_benchmark.fit(X_train,y_train)\n",
    "pred_mlpc_benchmark=mlpc_benchmark.predict(X_test) #around 5 mins tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    8    5 ...   35  410    2]\n",
      " [   0   19    6 ...   39  455    3]\n",
      " [   0    9   51 ...   51  409    0]\n",
      " ...\n",
      " [   0    4    1 ... 2833  508   47]\n",
      " [   0   11    5 ...  268 4688    7]\n",
      " [   0    0    0 ...  641   54  134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       583\n",
      "           1       0.09      0.03      0.04       710\n",
      "           2       0.29      0.08      0.13       634\n",
      "           3       0.57      0.32      0.41       453\n",
      "           4       0.00      0.00      0.00       205\n",
      "           5       0.11      0.00      0.01       588\n",
      "           6       0.84      0.10      0.18       212\n",
      "           7       0.08      0.00      0.00       441\n",
      "           8       0.86      0.74      0.79       859\n",
      "           9       0.00      0.00      0.00       433\n",
      "          10       0.00      0.00      0.00       337\n",
      "          11       0.00      0.00      0.00       290\n",
      "          12       0.14      0.01      0.02       487\n",
      "          13       0.92      0.58      0.71       253\n",
      "          14       0.28      0.42      0.33      1222\n",
      "          15       0.53      0.33      0.40       380\n",
      "          16       0.00      0.00      0.00       220\n",
      "          17       0.01      0.00      0.00       693\n",
      "          18       0.12      0.06      0.08       825\n",
      "          19       0.00      0.00      0.00       238\n",
      "          20       0.45      0.36      0.40       547\n",
      "          21       0.05      0.00      0.00       566\n",
      "          22       0.82      0.68      0.75       544\n",
      "          23       0.68      0.56      0.62       262\n",
      "          24       0.83      0.74      0.78       364\n",
      "          25       0.00      0.00      0.00       227\n",
      "          26       0.71      0.76      0.73      2909\n",
      "          27       0.65      0.36      0.46       321\n",
      "          28       0.00      0.00      0.00       210\n",
      "          29       0.36      0.31      0.33       673\n",
      "          30       0.77      0.82      0.79       456\n",
      "          31       0.00      0.00      0.00       232\n",
      "          32       0.96      0.29      0.45       170\n",
      "          33       0.20      0.01      0.02       575\n",
      "          34       0.00      0.00      0.00       187\n",
      "          35       0.84      0.07      0.12       246\n",
      "          36       0.43      0.15      0.22       458\n",
      "          37       0.50      0.21      0.30       378\n",
      "          38       0.50      0.10      0.16       342\n",
      "          39       0.53      0.33      0.40       212\n",
      "          40       0.64      0.33      0.43       255\n",
      "          41       0.52      0.20      0.29       256\n",
      "          42       0.71      0.49      0.58       364\n",
      "          43       0.72      0.23      0.35       203\n",
      "          44       0.52      0.30      0.38       478\n",
      "          45       0.70      0.34      0.46       267\n",
      "          46       0.57      0.81      0.67      3479\n",
      "          47       0.32      0.90      0.47      5212\n",
      "          48       0.59      0.16      0.25       837\n",
      "\n",
      "   micro avg       0.45      0.45      0.45     31293\n",
      "   macro avg       0.40      0.25      0.28     31293\n",
      "weighted avg       0.42      0.45      0.38     31293\n",
      "\n",
      "0.4525932317131627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rashid/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#METRICS\n",
    "print(confusion_matrix(y_test,pred_mlpc_benchmark))\n",
    "print(classification_report(y_test,pred_mlpc_benchmark))\n",
    "acc_mlpc_benchmark=accuracy_score(y_test,pred_mlpc_benchmark) #result for svm\n",
    "print(acc_mlpc_benchmark) #print precision score \n",
    "#results matches in the paper where accuracy is 68.3 ± 0.60, macro F1 is 50.4 ± 0.71. Took 4-5 minutes on macbook pro 2.7 GHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FFNN_MOA_FullCurated_Tuned']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(mlpc_benchmark,'FFNN_MOA_FullCurated_Tuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
